{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f791b120-0b56-4a45-8203-cf5687787201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185cc82c-caf1-40a7-8ad5-0736b54de495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:23:33.551Z\",\"msg_id\":\"b36cf3be-9bef-4b60-ab08-98b78d4243c8\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {\"cellId\":\"vscode-notebook-cell:/c%3A/Users/aleks/Desktop/Python/AI/definicje/definicje.ipynb#W2sZmlsZQ%3D%3D\"}\n",
      "znajdzka {\"silent\":false,\"store_history\":true,\"user_expressions\":{},\"allow_stdin\":true,\"stop_on_error\":false,\"code\":\"data = pd.read_excel('definicje-ap.xlsx', sheet_name=['stanford','stanford-nontheses'])\"}\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('definicje-ap.xlsx', sheet_name=['stanford','stanford-nontheses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1099c905-e792-4f2c-b984-c735d0441911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:23:35.412Z\",\"msg_id\":\"3b0856bf-9063-4f6e-8cbc-074a20835dc2\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {\"cellId\":\"vscode-notebook-cell:/c%3A/Users/aleks/Desktop/Python/AI/definicje/definicje.ipynb#W3sZmlsZQ%3D%3D\"}\n",
      "znajdzka {\"silent\":false,\"store_history\":true,\"user_expressions\":{},\"allow_stdin\":true,\"stop_on_error\":false,\"code\":\"data\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'stanford':     Most philosophers agree that abduction (in the sense of Inference to the Best Explanation) is a type of inference that is frequently employed, in some form or other, both in everyday and in scientific reasoning.\n",
       " 0    To say that something is authentic is to say t...                                                                                                                                                                 \n",
       " 1    Donald Davidson [1980, essay 3] asserted that ...                                                                                                                                                                 \n",
       " 2    “Adaptationism” refers to a family of views ab...                                                                                                                                                                 \n",
       " 3    Behaviorism is built on this assumption, and i...                                                                                                                                                                 \n",
       " 4    The epistemic basing relation is the relation ...                                                                                                                                                                 \n",
       " ..                                                 ...                                                                                                                                                                 \n",
       " 96                                                 NaN                                                                                                                                                                 \n",
       " 97                                                 NaN                                                                                                                                                                 \n",
       " 98                                                 NaN                                                                                                                                                                 \n",
       " 99                                                 NaN                                                                                                                                                                 \n",
       " 100  Zombies in philosophy are imaginary creatures ...                                                                                                                                                                 \n",
       " \n",
       " [101 rows x 1 columns],\n",
       " 'stanford-nontheses':     It is standard practice to group non-necessary inferences into inductive and abductive ones.\n",
       " 0    With these social changes there is a sharp shi...                                          \n",
       " 1    It is frequently noted that the agent has some...                                          \n",
       " 2    There were two central but mainly disjunct sci...                                          \n",
       " 3    According to methodological behaviorism, refer...                                          \n",
       " 4    A belief is causally sustained by a reason whe...                                          \n",
       " ..                                                 ...                                          \n",
       " 96   After their 1945 paper, it was not clear that ...                                          \n",
       " 97   The rational egoist might reply that the instr...                                          \n",
       " 98   But there are other points of view, such as th...                                          \n",
       " 99   This same “identity in difference” of original...                                          \n",
       " 100  We noted above that at least many philosophers...                                          \n",
       " \n",
       " [101 rows x 1 columns]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b2db8f-3b56-4fcf-9d80-07c83bba0d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:24:00.866Z\",\"msg_id\":\"aaa873d8-f0b7-4df4-b709-bf3e21b40c5f\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {\"cellId\":\"vscode-notebook-cell:/c%3A/Users/aleks/Desktop/Python/AI/definicje/definicje.ipynb#W4sZmlsZQ%3D%3D\"}\n",
      "znajdzka {\"silent\":false,\"store_history\":true,\"user_expressions\":{},\"allow_stdin\":true,\"stop_on_error\":false,\"code\":\"stanford_df = data.get('stanford')\\nstanford_nontheses_df = data.get('stanford-nontheses')\"}\n"
     ]
    }
   ],
   "source": [
    "stanford_df = data.get('stanford')\n",
    "stanford_nontheses_df = data.get('stanford-nontheses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "258db662-a6c8-4dde-b6a7-846e021e9347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:24:02.393Z\",\"msg_id\":\"c866b5a0-bf21-4316-b24d-eaa53e9d62f1\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {\"cellId\":\"vscode-notebook-cell:/c%3A/Users/aleks/Desktop/Python/AI/definicje/definicje.ipynb#W5sZmlsZQ%3D%3D\"}\n",
      "znajdzka {\"silent\":false,\"store_history\":true,\"user_expressions\":{},\"allow_stdin\":true,\"stop_on_error\":false,\"code\":\"stanford_df.head()\"}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Most philosophers agree that abduction (in the sense of Inference to the Best Explanation) is a type of inference that is frequently employed, in some form or other, both in everyday and in scientific reasoning.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To say that something is authentic is to say t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Davidson [1980, essay 3] asserted that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“Adaptationism” refers to a family of views ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Behaviorism is built on this assumption, and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The epistemic basing relation is the relation ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Most philosophers agree that abduction (in the sense of Inference to the Best Explanation) is a type of inference that is frequently employed, in some form or other, both in everyday and in scientific reasoning.\n",
       "0  To say that something is authentic is to say t...                                                                                                                                                                 \n",
       "1  Donald Davidson [1980, essay 3] asserted that ...                                                                                                                                                                 \n",
       "2  “Adaptationism” refers to a family of views ab...                                                                                                                                                                 \n",
       "3  Behaviorism is built on this assumption, and i...                                                                                                                                                                 \n",
       "4  The epistemic basing relation is the relation ...                                                                                                                                                                 "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanford_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0ab98ee-16ea-4e85-99ef-d45bdc99dc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:24:04.619Z\",\"msg_id\":\"4952e0a6-2303-4070-a767-878b6e49d3f8\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {\"cellId\":\"vscode-notebook-cell:/c%3A/Users/aleks/Desktop/Python/AI/definicje/definicje.ipynb#W6sZmlsZQ%3D%3D\"}\n",
      "znajdzka {\"silent\":false,\"store_history\":true,\"user_expressions\":{},\"allow_stdin\":true,\"stop_on_error\":false,\"code\":\"convert_data = {}\\nfor row in stanford_df:\\n    \\n    if 'definition' not in convert_data:\\n        convert_data['definition'] = [row]\\n    \\n    print(stanford_df[row])\\n    convert_data['definition'].extend(stanford_df[row])\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      To say that something is authentic is to say t...\n",
      "1      Donald Davidson [1980, essay 3] asserted that ...\n",
      "2      “Adaptationism” refers to a family of views ab...\n",
      "3      Behaviorism is built on this assumption, and i...\n",
      "4      The epistemic basing relation is the relation ...\n",
      "                             ...                        \n",
      "96                                                   NaN\n",
      "97                                                   NaN\n",
      "98                                                   NaN\n",
      "99                                                   NaN\n",
      "100    Zombies in philosophy are imaginary creatures ...\n",
      "Name: Most philosophers agree that abduction (in the sense of Inference to the Best Explanation) is a type of inference that is frequently employed, in some form or other, both in everyday and in scientific reasoning., Length: 101, dtype: object\n"
     ]
    }
   ],
   "source": [
    "convert_data = {}\n",
    "for row in stanford_df:\n",
    "    \n",
    "    if 'definition' not in convert_data:\n",
    "        convert_data['definition'] = [row]\n",
    "    \n",
    "    print(stanford_df[row])\n",
    "    convert_data['definition'].extend(stanford_df[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e352f02-bbcd-42a8-b832-a68da1ba4862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:24:08.812Z\",\"msg_id\":\"93aeff28-1ead-41af-952b-46ba8d7ed855\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {\"cellId\":\"vscode-notebook-cell:/c%3A/Users/aleks/Desktop/Python/AI/definicje/definicje.ipynb#X10sZmlsZQ%3D%3D\"}\n",
      "znajdzka {\"silent\":false,\"store_history\":true,\"user_expressions\":{},\"allow_stdin\":true,\"stop_on_error\":false,\"code\":\"for row in stanford_nontheses_df:\\n    if 'no_definition' not in convert_data:\\n        convert_data['no_definition'] = [row]\\n    convert_data['no_definition'].extend(stanford_nontheses_df[row])\"}\n"
     ]
    }
   ],
   "source": [
    "for row in stanford_nontheses_df:\n",
    "    if 'no_definition' not in convert_data:\n",
    "        convert_data['no_definition'] = [row]\n",
    "    convert_data['no_definition'].extend(stanford_nontheses_df[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e20aa6c8-34b7-487d-b68f-eb3d3fbfecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:24:10.408Z\",\"msg_id\":\"8d3191f9-33e0-4733-a87a-17f900e4d2fd\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {\"cellId\":\"vscode-notebook-cell:/c%3A/Users/aleks/Desktop/Python/AI/definicje/definicje.ipynb#X11sZmlsZQ%3D%3D\"}\n",
      "znajdzka {\"silent\":false,\"store_history\":true,\"user_expressions\":{},\"allow_stdin\":true,\"stop_on_error\":false,\"code\":\"len(convert_data['definition'])\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(convert_data['definition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0506e1-becf-472d-80e2-7feb5ef45ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:24:11.529Z\",\"msg_id\":\"0a978ce1-c9cc-4b30-a685-d457cd91fa14\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {\"cellId\":\"vscode-notebook-cell:/c%3A/Users/aleks/Desktop/Python/AI/definicje/definicje.ipynb#X12sZmlsZQ%3D%3D\"}\n",
      "znajdzka {\"silent\":false,\"store_history\":true,\"user_expressions\":{},\"allow_stdin\":true,\"stop_on_error\":false,\"code\":\"len(convert_data['no_definition'])\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(convert_data['no_definition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "895845d6-696a-44da-b00e-2fc4018edfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:24:12.939Z\",\"msg_id\":\"5c743262-e6aa-4fa3-a953-fbb9c5b72be3\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {\"cellId\":\"vscode-notebook-cell:/c%3A/Users/aleks/Desktop/Python/AI/definicje/definicje.ipynb#X13sZmlsZQ%3D%3D\"}\n",
      "znajdzka {\"silent\":false,\"store_history\":true,\"user_expressions\":{},\"allow_stdin\":true,\"stop_on_error\":false,\"code\":\"df = pd.DataFrame(data=convert_data)\"}\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data=convert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42891e4b-912c-4e95-86a2-92e0f20a0a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['definition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0512c072-b4ca-4e74-b6f2-1c51f8be33da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>definition</th>\n",
       "      <th>no_definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Most philosophers agree that abduction (in the...</td>\n",
       "      <td>It is standard practice to group non-necessary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To say that something is authentic is to say t...</td>\n",
       "      <td>With these social changes there is a sharp shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Davidson [1980, essay 3] asserted that ...</td>\n",
       "      <td>It is frequently noted that the agent has some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“Adaptationism” refers to a family of views ab...</td>\n",
       "      <td>There were two central but mainly disjunct sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Behaviorism is built on this assumption, and i...</td>\n",
       "      <td>According to methodological behaviorism, refer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>After their 1945 paper, it was not clear that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The rational egoist might reply that the instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>But there are other points of view, such as th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>This same “identity in difference” of original...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Zombies in philosophy are imaginary creatures ...</td>\n",
       "      <td>We noted above that at least many philosophers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            definition  \\\n",
       "0    Most philosophers agree that abduction (in the...   \n",
       "1    To say that something is authentic is to say t...   \n",
       "2    Donald Davidson [1980, essay 3] asserted that ...   \n",
       "3    “Adaptationism” refers to a family of views ab...   \n",
       "4    Behaviorism is built on this assumption, and i...   \n",
       "..                                                 ...   \n",
       "97                                                 NaN   \n",
       "98                                                 NaN   \n",
       "99                                                 NaN   \n",
       "100                                                NaN   \n",
       "101  Zombies in philosophy are imaginary creatures ...   \n",
       "\n",
       "                                         no_definition  \n",
       "0    It is standard practice to group non-necessary...  \n",
       "1    With these social changes there is a sharp shi...  \n",
       "2    It is frequently noted that the agent has some...  \n",
       "3    There were two central but mainly disjunct sci...  \n",
       "4    According to methodological behaviorism, refer...  \n",
       "..                                                 ...  \n",
       "97   After their 1945 paper, it was not clear that ...  \n",
       "98   The rational egoist might reply that the instr...  \n",
       "99   But there are other points of view, such as th...  \n",
       "100  This same “identity in difference” of original...  \n",
       "101  We noted above that at least many philosophers...  \n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T12:53:14.355Z\",\"msg_id\":\"a661457d-5ae7-42ba-ac6c-020a02a51ca6\",\"msg_type\":\"complete_request\",\"session\":\"bb12cdc8-da52-41d7-97ff-dd2cc9a13604\",\"username\":\"\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {}\n",
      "znajdzka {\"code\":\"def make_bag_of_words(data:pd.DataFrame)->dict:\\n    bag_of_words = {}\\n    words = data.to\\n    for lbl in data:\",\"cursor_pos\":89}\n"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18afe5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:26:44.210Z\",\"msg_id\":\"881e3a1f-6c39-49d0-9f03-e5f47524e62b\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {}\n",
      "znajdzka {\"silent\":false,\"store_history\":false,\"user_expressions\":{},\"allow_stdin\":false,\"stop_on_error\":false,\"code\":\"def __jupyter_exec_background__():\\n    from IPython.display import display\\n    from threading import Thread\\n    from traceback import format_exc\\n\\n    # First send a dummy response to get the display id.\\n    # Later we'll send the real response with the actual data.\\n    # And that can happen much later even after the execution completes,\\n    # as that response will be sent from a bg thread.\\n    output = display({\\\"application/vnd.vscode.bg.execution.10\\\": \\\"\\\"}, raw=True, display_id=True)\\n\\n    def do_implementation():\\n        return get_ipython().kernel.do_complete(\\\"t\\\", 1)\\n\\n    def bg_main():\\n        try:\\n            output.update({\\\"application/vnd.vscode.bg.execution.10.result\\\": do_implementation()}, raw=True)\\n        except Exception as e:\\n            output.update({\\\"application/vnd.vscode.bg.execution.10.error\\\": format_exc()}, raw=True)\\n\\n\\n    Thread(target=bg_main, daemon=True).start()\\n\\n\\n__jupyter_exec_background__()\\ndel __jupyter_exec_background__\"}\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2237d40e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "word_tokenize() missing 1 required positional argument: 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: word_tokenize() missing 1 required positional argument: 'text'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:27:20.464Z\",\"msg_id\":\"445efc06-04c7-4ee6-86c0-7b628b03ca58\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {}\n",
      "znajdzka {\"silent\":false,\"store_history\":false,\"user_expressions\":{},\"allow_stdin\":false,\"stop_on_error\":false,\"code\":\"def __jupyter_exec_background__():\\n    from IPython.display import display\\n    from threading import Thread\\n    from traceback import format_exc\\n\\n    # First send a dummy response to get the display id.\\n    # Later we'll send the real response with the actual data.\\n    # And that can happen much later even after the execution completes,\\n    # as that response will be sent from a bg thread.\\n    output = display({\\\"application/vnd.vscode.bg.execution.14\\\": \\\"\\\"}, raw=True, display_id=True)\\n\\n    def do_implementation():\\n        return get_ipython().kernel.do_complete(\\\"def make_bag_of_words(data:pd.DataFrame)->dict:\\\\r\\\\n    bag_of_words = {}\\\\r\\\\n    words = data.to_dict('records')\\\\r\\\\n    for lbl in words:\\\\r\\\\n        f\\\", 141)\\n\\n    def bg_main():\\n        try:\\n            output.update({\\\"application/vnd.vscode.bg.execution.14.result\\\": do_implementation()}, raw=True)\\n        except Exception as e:\\n            output.update({\\\"application/vnd.vscode.bg.execution.14.error\\\": format_exc()}, raw=True)\\n\\n\\n    Thread(target=bg_main, daemon=True).start()\\n\\n\\n__jupyter_exec_background__()\\ndel __jupyter_exec_background__\"}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = word_tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72878eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lazy', 'dog', 'jump', 'over', 'fluffy', 'fox', '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:32:32.172Z\",\"msg_id\":\"256884d7-0296-4cd5-a20e-efc5c2188001\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {}\n",
      "znajdzka {\"silent\":false,\"store_history\":false,\"user_expressions\":{},\"allow_stdin\":false,\"stop_on_error\":false,\"code\":\"def __jupyter_exec_background__():\\n    from IPython.display import display\\n    from threading import Thread\\n    from traceback import format_exc\\n\\n    # First send a dummy response to get the display id.\\n    # Later we'll send the real response with the actual data.\\n    # And that can happen much later even after the execution completes,\\n    # as that response will be sent from a bg thread.\\n    output = display({\\\"application/vnd.vscode.bg.execution.55\\\": \\\"\\\"}, raw=True, display_id=True)\\n\\n    def do_implementation():\\n        return get_ipython().kernel.do_complete(\\\"def make_bag_of_words(data:pd.DataFrame)->dict:\\\\r\\\\n    bag_of_words = {}\\\\r\\\\n    words = data.to_dict('records')\\\\r\\\\n    for lbl in words:\\\\r\\\\n        for sent in lbl.values():\\\\r\\\\n            p\\\\r\\\\n            words = word_tokenize(sent)\\\\r\\\\n            for word in words:\\\\r\\\\n                if word not in bag_of_words:\\\\r\\\\n                    bag_of_words[word] = 0\\\\r\\\\n                else:\\\\r\\\\n                    bag_of_words[word]+=1\\\\r\\\\n    return bag_of_words\\\", 180)\\n\\n    def bg_main():\\n        try:\\n            output.update({\\\"application/vnd.vscode.bg.execution.55.result\\\": do_implementation()}, raw=True)\\n        except Exception as e:\\n            output.update({\\\"application/vnd.vscode.bg.execution.55.error\\\": format_exc()}, raw=True)\\n\\n\\n    Thread(target=bg_main, daemon=True).start()\\n\\n\\n__jupyter_exec_background__()\\ndel __jupyter_exec_background__\"}\n"
     ]
    }
   ],
   "source": [
    "word_tokenize('Lazy dog jump over fluffy fox.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87b882d5-f978-455e-9dbf-8458a7df9784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:34:09.081Z\",\"msg_id\":\"e3b5d45d-c860-4bdf-89fa-62dde2116c9e\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {\"cellId\":\"vscode-notebook-cell:/c%3A/Users/aleks/Desktop/Python/AI/definicje/definicje.ipynb#X16sZmlsZQ%3D%3D\"}\n",
      "znajdzka {\"silent\":false,\"store_history\":true,\"user_expressions\":{},\"allow_stdin\":true,\"stop_on_error\":false,\"code\":\"def make_bag_of_words(data:pd.DataFrame)->dict:\\n    bag_of_words = {}\\n    data = data.to_dict('records')\\n    print(data[0]['definition'])\\n    for lbl in data:\\n        for sent in lbl.values():\\n            words = word_tokenize(sent)\\n            for word in words:\\n                if word not in bag_of_words:\\n                    bag_of_words[word] = 0\\n                else:\\n                    bag_of_words[word]+=1\\n    return bag_of_words\"}\n"
     ]
    }
   ],
   "source": [
    "def make_bag_of_words(data:pd.DataFrame)->dict:\n",
    "    bag_of_words = {}\n",
    "    data = data.to_dict('records')\n",
    "    print(data[0]['definition'])\n",
    "    for lbl in data:\n",
    "        for sent in lbl.values():\n",
    "            words = word_tokenize(sent)\n",
    "            for word in words:\n",
    "                if word not in bag_of_words:\n",
    "                    bag_of_words[word] = 0\n",
    "                else:\n",
    "                    bag_of_words[word]+=1\n",
    "    return bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7399cde-4fb9-4dfe-a737-63aa683d3dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "znajdzka {\"date\":\"2024-10-07T18:34:10.153Z\",\"msg_id\":\"04b76118-45d8-49d3-9b39-5ce68a7b930b\",\"msg_type\":\"execute_request\",\"session\":\"9322afaa-1264-4f7c-a7e0-99156304b2b0\",\"username\":\"aa955429-2d1b-4904-9f2a-a5d14a9f649a\",\"version\":\"5.2\"}\n",
      "znajdzka {}\n",
      "znajdzka {\"cellId\":\"vscode-notebook-cell:/c%3A/Users/aleks/Desktop/Python/AI/definicje/definicje.ipynb#X20sZmlsZQ%3D%3D\"}\n",
      "znajdzka {\"silent\":false,\"store_history\":true,\"user_expressions\":{},\"allow_stdin\":true,\"stop_on_error\":false,\"code\":\"make_bag_of_words(df)\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most philosophers agree that abduction (in the sense of Inference to the Best Explanation) is a type of inference that is frequently employed, in some form or other, both in everyday and in scientific reasoning.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmake_bag_of_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 7\u001b[0m, in \u001b[0;36mmake_bag_of_words\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lbl \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m lbl\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m----> 7\u001b[0m         words \u001b[38;5;241m=\u001b[39m \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[0;32m      9\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m bag_of_words:\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\budget-manager\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    145\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\budget-manager\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:120\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03mReturn a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03musing NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m:param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m _get_punkt_tokenizer(language)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\budget-manager\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1280\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;124;03m    Given a text, returns a list of the sentences in that text.\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentences_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealign_boundaries\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\budget-manager\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1340\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.sentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43me\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspan_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealign_boundaries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\budget-manager\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1340\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43me\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspan_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealign_boundaries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\budget-manager\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1328\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.span_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m realign_boundaries:\n\u001b[0;32m   1327\u001b[0m     slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_realign_boundaries(text, slices)\n\u001b[1;32m-> 1328\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mslices\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\budget-manager\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1457\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;124;03mAttempts to realign punctuation that falls after the period but\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03mshould otherwise be included in the same sentence.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;124;03m    [\"(Sent1.)\", \"Sent2.\"].\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m realign \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1457\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_pair_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m    \u001b[49m\u001b[43msentence1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msentence1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrealign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence2\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\budget-manager\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:321\u001b[0m, in \u001b[0;36m_pair_iter\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    319\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterator)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 321\u001b[0m     prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\budget-manager\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1429\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_slices_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mslice\u001b[39m]:\n\u001b[0;32m   1428\u001b[0m     last_break \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1429\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_match_potential_end_contexts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1430\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_contains_sentbreak\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlast_break\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\envs\\budget-manager\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1394\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._match_potential_end_contexts\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1392\u001b[0m previous_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1393\u001b[0m previous_match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1394\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lang_vars\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperiod_context_re\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1395\u001b[0m     \u001b[38;5;66;03m# Get the slice of the previous word\u001b[39;00m\n\u001b[0;32m   1396\u001b[0m     before_text \u001b[38;5;241m=\u001b[39m text[previous_slice\u001b[38;5;241m.\u001b[39mstop : match\u001b[38;5;241m.\u001b[39mstart()]\n\u001b[0;32m   1397\u001b[0m     index_after_last_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_last_whitespace_index(before_text)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object, got 'float'"
     ]
    }
   ],
   "source": [
    "make_bag_of_words(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b36b5-e54d-456e-8abf-f2241dde0f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
